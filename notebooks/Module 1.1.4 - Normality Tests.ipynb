{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantitative Finance\n",
    "\n",
    "Copyright (c) 2019 Python Charmers Pty Ltd, Australia, <https://pythoncharmers.com>. All rights reserved.\n",
    "\n",
    "<img src=\"img/python_charmers_logo.png\" width=\"300\" alt=\"Python Charmers Logo\">\n",
    "\n",
    "Published under the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license. See `LICENSE.md` for details.\n",
    "\n",
    "Sponsored by Tibra Global Services, <https://tibra.com>\n",
    "\n",
    "<img src=\"img/tibra_logo.png\" width=\"300\" alt=\"Tibra Logo\">\n",
    "\n",
    "\n",
    "## Module 1.1: Distributions and Random Processes\n",
    "\n",
    "### 1.1.4: Normality Tests\n",
    "\n",
    "If you are analysing data on the assumption it is normally distributed, you should test that assumption first. Properties of normal distributions do not necessarily apply to data that has a different underlying distribution. As an example, an ANOVA test assumes normality in your data, and the results of an ANOVA are not valid if the data comes from some other source.\n",
    "\n",
    "There are a number of normality tests that provide a way for us to determine if it is likely that the data comes from a normal distribution.\n",
    "\n",
    "One method of testing for normality is to compute the skew and kurtosis of the data. A standard normal distribution has a skew of 0 and a kurtosis of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not convert 'Open' to NumPy timedelta",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:433\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.array_to_timedelta64\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:465\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64_fastpath\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:637\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.parse_timedelta_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unit abbreviation w/o a number",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:473\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:356\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.convert_to_timedelta64\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:637\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.parse_timedelta_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unit abbreviation w/o a number",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m aapl \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_hdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/AAPL.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:442\u001b[0m, in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    438\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey must be provided when HDF5 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile contains multiple datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m                 )\n\u001b[0;32m    441\u001b[0m         key \u001b[38;5;241m=\u001b[39m candidate_only_group\u001b[38;5;241m.\u001b[39m_v_pathname\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_close\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, HDFStore):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;66;03m# if there is an error, close the store if we opened it.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:872\u001b[0m, in \u001b[0;36mHDFStore.select\u001b[1;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;66;03m# create the iterator\u001b[39;00m\n\u001b[0;32m    859\u001b[0m it \u001b[38;5;241m=\u001b[39m TableIterator(\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    861\u001b[0m     s,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    869\u001b[0m     auto_close\u001b[38;5;241m=\u001b[39mauto_close,\n\u001b[0;32m    870\u001b[0m )\n\u001b[1;32m--> 872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:1947\u001b[0m, in \u001b[0;36mTableIterator.get_result\u001b[1;34m(self, coordinates)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     where \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# directly return the result\u001b[39;00m\n\u001b[1;32m-> 1947\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:856\u001b[0m, in \u001b[0;36mHDFStore.select.<locals>.func\u001b[1;34m(_start, _stop, _where)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(_start, _stop, _where):\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_where\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:3219\u001b[0m, in \u001b[0;36mBlockManagerFixed.read\u001b[1;34m(self, where, columns, start, stop)\u001b[0m\n\u001b[0;32m   3215\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnblocks):\n\u001b[1;32m-> 3219\u001b[0m     blk_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblock\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_items\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3220\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, start\u001b[38;5;241m=\u001b[39m_start, stop\u001b[38;5;241m=\u001b[39m_stop)\n\u001b[0;32m   3222\u001b[0m     columns \u001b[38;5;241m=\u001b[39m items[items\u001b[38;5;241m.\u001b[39mget_indexer(blk_items)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:2917\u001b[0m, in \u001b[0;36mGenericFixed.read_index\u001b[1;34m(self, key, start, stop)\u001b[0m\n\u001b[0;32m   2915\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m variety \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregular\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2916\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, key)\n\u001b[1;32m-> 2917\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_index_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[0;32m   2919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\pytables.py:3020\u001b[0m, in \u001b[0;36mGenericFixed.read_index_node\u001b[1;34m(self, node, start, stop)\u001b[0m\n\u001b[0;32m   3012\u001b[0m     index \u001b[38;5;241m=\u001b[39m factory(\n\u001b[0;32m   3013\u001b[0m         _unconvert_index(\n\u001b[0;32m   3014\u001b[0m             data, kind, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3018\u001b[0m     )\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3020\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3021\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_unconvert_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3027\u001b[0m index\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\timedeltas.py:153\u001b[0m, in \u001b[0;36mTimedeltaIndex.__new__\u001b[1;34m(cls, data, unit, freq, closed, dtype, copy, name)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39m_view()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# - Cases checked above all return/raise before reaching here - #\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m tdarr \u001b[38;5;241m=\u001b[39m \u001b[43mTimedeltaArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence_not_strict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_new(tdarr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:224\u001b[0m, in \u001b[0;36mTimedeltaArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, freq, unit)\u001b[0m\n\u001b[0;32m    220\u001b[0m freq \u001b[38;5;241m=\u001b[39m freq \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    222\u001b[0m freq, freq_infer \u001b[38;5;241m=\u001b[39m dtl\u001b[38;5;241m.\u001b[39mmaybe_infer_freq(freq)\n\u001b[1;32m--> 224\u001b[0m data, inferred_freq \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_td64ns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m freq, freq_infer \u001b[38;5;241m=\u001b[39m dtl\u001b[38;5;241m.\u001b[39mvalidate_inferred_freq(freq, inferred_freq, freq_infer)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explicit_none:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:894\u001b[0m, in \u001b[0;36msequence_to_td64ns\u001b[1;34m(data, copy, unit, errors)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Convert whatever we have into timedelta64[ns] dtype\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(data\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_string_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# no need to make a copy, need to convert if string-dtyped\u001b[39;00m\n\u001b[1;32m--> 894\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_objects_to_td64ns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# treat as multiples of the given unit\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:1004\u001b[0m, in \u001b[0;36m_objects_to_td64ns\u001b[1;34m(data, unit, errors)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# coerce Index to np.ndarray, converting string-dtype if necessary\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1004\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43marray_to_timedelta64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimedelta64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:447\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.array_to_timedelta64\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx:480\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not convert 'Open' to NumPy timedelta"
     ]
    }
   ],
   "source": [
    "aapl = pd.read_hdf(\"data/AAPL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl['Gain'] = aapl['Adj Close'].diff()\n",
    "aapl.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991757323146919"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.skew(aapl['Gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.446941304720326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kurtosis(aapl['Gain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AAPL stock price increases do not appear to have a normal distribution based on this data. Let's have a look at the histogram again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f8ab423273c84e4c85a4994733d23082\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f8ab423273c84e4c85a4994733d23082\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f8ab423273c84e4c85a4994733d23082\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-8d4b91037c6feceeefff91e21fd845d7.json\", \"format\": {\"type\": \"json\"}}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"bin\": {\"maxbins\": 100}, \"field\": \"Gain\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(aapl).mark_bar().encode(\n",
    "        alt.X(\"Gain\", bin=alt.Bin(maxbins=100)),\n",
    "        y='count()',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high Kurtosis is obtained from very \"sharp\" peaks such as this one. The skew is not that high, but is positive, indicating a right-leaning distribution.\n",
    "\n",
    "More objective tests are available in the `scipy.stats` package. For instance, the Shapiro-Wilk test is commonly used and is a good test for small to medium datasets, with up to a few thousand data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p = stats.shapiro(aapl['Gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p  # Compare the p value to your acceptable alpha value to determine if the null hypothesis can be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data does not look like it was drawn from a normal distribution\n"
     ]
    }
   ],
   "source": [
    "if p > 0.05:\n",
    "    print(\"The data looks like it was drawn from a normal distribution\")\n",
    "else:\n",
    "    print(\"The data does not look like it was drawn from a normal distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a p-value?\n",
    "\n",
    "The p-value above is a commonly used term to describe the probability of your test being true.\n",
    "\n",
    "As it is a probability, it has a value between 0 and 1. Values near 0 indicate that your test is \"not likely to be true\" and values near 1 indicate that your test is likely to be true. Often, we apply a threshold, and if our p value is greater than that threshold, we accept the outcome as \"likely enough, and we continue as if it were true\", that is, we accept the outcome of the test as a \"positive\".\n",
    "\n",
    "It is very common to use a threshold of 0.05 when performing a test. That is, if our test has a greater than 95% chance of being true, we accept it as such. While this is an adequate rule of thumb, it is not a one-size-fits-all solution to the problem of choosing a p value threshold.\n",
    "\n",
    "Where this is normally seen in classical statistics is with a Null, and Alternative hypothesis. We will delve into these deeper later, but as this is used above, the null hypothesis is our \"nothing is surprising\" hypothesis, and the alternative is \"there is something interesting here\". For the Shapiro-Wilk used above, the hypothesis are:\n",
    "\n",
    "* $H_0$ (the Null hypothesis): The data is drawn from a normal distribution\n",
    "* $H_A$ (the Alternative hypothesis): The data was not drawn from a normal distribution\n",
    "\n",
    "Here we have mutually exclusive tests. If we get a value of $a$ for our Null hypothesis, then the probability of our Alternative being true is $1-a$. Statisticians are a pessemistic bunch, so require a very high threshold before we reject the Null hypothesis. This is akin to requiring a very high amount of evidence to reject it. Therefore, to reject the Null hypothesis, to indicate something else is going on here, we require the p value to be less than 0.05, i.e. for there to be a greater than 95% chance the Alternative hypothesis is true.\n",
    "\n",
    "This might seem like a high standard to meet, but humans often see patterns in data that are not there. We use statistics to test these patterns and ensure we don't fall afoul of this over confident pattern matching.\n",
    "\n",
    "Before you decide to run a new statistical test, you should see first what the p value would tell you. Often the language is \"accept the null hypothesis\" or \"fail to accept the null hypothesis\". This will tell you how to use the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see from the Kurtosis that this dataset above wasn't normal. Let's look at a different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = np.array([\n",
    "    205.61624376, 155.80577135, 202.09636984, 159.19312848,\n",
    "    160.0263383 , 147.44200373, 160.96891569, 160.76304892,\n",
    "    167.59165377, 164.31571823, 151.11269914, 176.43856129,\n",
    "    176.88435091, 138.04177187, 183.87507305, 162.81488426,\n",
    "    167.96767641, 144.68437342, 180.88771461, 179.18997091,\n",
    "    189.81672505, 163.68662119, 175.70135072, 167.32793289,\n",
    "    163.72509862, 207.93257342, 177.41722601, 167.28154916,\n",
    "    170.26294662, 187.01142671, 178.3108478 , 168.8711774 ,\n",
    "    202.77222671, 138.55043572, 187.10284379, 155.13494037,\n",
    "    175.24219374, 188.54739561, 191.42024196, 174.34537673,\n",
    "    158.36285104, 183.17014557, 166.36310929, 185.3415384 ,\n",
    "    163.87673308, 173.70401469, 168.78499868, 167.39762991,\n",
    "    166.89193943, 191.04035344, 148.02108024, 140.82772936,\n",
    "    168.85378921, 142.13536543, 189.77084606, 173.7849811 ,\n",
    "    157.61303804, 171.62493617, 173.30529631, 162.92083214,\n",
    "    169.52974326, 142.01039665, 176.01691215, 170.32439763,\n",
    "    172.64616031, 158.35076247, 185.96332979, 176.6176222 ,\n",
    "    204.68516079, 161.43591954, 172.42384543, 179.36900257,\n",
    "    170.01353653, 194.40269002, 139.96802012, 156.47281846,\n",
    "    210.21895193, 153.30508193, 157.10282665, 200.07040619,\n",
    "    174.69616438, 168.97403285, 188.9396949 , 156.19358617,\n",
    "    179.56494356, 175.04014032, 164.1384659 , 167.90219562,\n",
    "    184.80752625, 143.56580744, 169.80537836, 186.5894398 ,\n",
    "    166.39251657, 165.65510886, 195.49137372, 152.21650272,\n",
    "    163.14001055, 170.27382512, 147.63901378, 190.32910286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p = stats.shapiro(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data looks like it was drawn from a normal distribution\n",
      "p=0.278\n"
     ]
    }
   ],
   "source": [
    "if p > 0.05:\n",
    "    print(\"The data looks like it was drawn from a normal distribution\")\n",
    "    print(\"p={:.3f}\".format(p))\n",
    "else:\n",
    "    print(\"The data does not look like it was drawn from a normal distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Two other commonly used tests for normality are available in `scipy.stats`. They are `stats.normaltest` and `stats.kstest`. Review the help and references for these functions, and run them on the `heights` data. What are the strengths and weaknesses of each test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6994130645220737 0.0\n",
      "From Stack overflow, the Kolmogorov-Smirnov is for a completely specified distribution, while the Shapiro-Wilk is for normality, with unspecified mean and variance.\n"
     ]
    }
   ],
   "source": [
    "statistic_chi, p_c = stats.normaltest(heights) #chi squared test statistic\n",
    "statistic_k, p_k = stats.kstest(heights,cdf = 'norm') #another one?\n",
    "print(str(p_c), str(p_k))\n",
    "\n",
    "print(\"From Stack overflow, the Kolmogorov-Smirnov is for a completely specified distribution, while the Shapiro-Wilk is for normality, with unspecified mean and variance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/scipy_normal_tests.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "\n",
    "We will now perform a normality test using the `statsmodels` package. This package allows for higher level statistics than the `scipy` module we have been using. We will be using `statsmodels` for much of the ordinary least squares computation in future modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p_value = sm.stats.diagnostic.kstest_normal(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data looks like it was drawn from a normal distribution\n",
      "p=0.200\n"
     ]
    }
   ],
   "source": [
    "if p_value > 0.05:\n",
    "    print(\"The data looks like it was drawn from a normal distribution\")\n",
    "    print(\"p={:.3f}\".format(p_value))\n",
    "else:\n",
    "    print(\"The data does not look like it was drawn from a normal distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Review the documentation for `statsmodels` at https://www.statsmodels.org and run the Jarque-Bera test for normality on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6714923453511482\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats import stattools\n",
    "\n",
    "jbstat, pvalue, skew, kurtosis = stattools.jarque_bera(heights)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/jarque_bera.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling conflicts\n",
    "\n",
    "There are many different normality tests. If you get the same result for all the tests (i.e. multiple tests suggest normal data), then you can be reasonably sure the data does come from a normal distribution.\n",
    "\n",
    "If you get conflicting result, the results are not quite so clear. In a conflicting case, it would be unlikely that the results will be wildly different. Instead, you are likely to get a few slightly \"above the line\" and a few slightly \"below the line\". Depending on the use case, you can interpret a single \"is normal\" result as being good enough. Much of the later analysis you can do will be fine for \"normal-like\" data, rather than strictly normal data.\n",
    "\n",
    "If you do have a very sensitive application that requires a great degree in confidence in your normality test, research further the assumptions behind different normality tests and see which are most applicable to your application. The SciPy and Statsmodels documentation contain references for each of the normality tests.\n",
    "\n",
    "A major property is the number of samples in your dataset. Some tests work better with more samples, and some work better with fewer. We will investigate this in the last exercise for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "We are going to investigate the relationship that sample size has with the results of a normality test. We want to test the likelihood a normality test will reject the normality hypothesis for a dataset that *actually is generated from a normal distribution*, as the sample size increases.\n",
    "\n",
    "Write a script that:\n",
    "\n",
    "1. Creates a normal distribution\n",
    "2. Randomly samples N data points from that distribution\n",
    "3. Checks for normality against four different normality tests\n",
    "4. Repeats steps 1-3 a large number of times, and with varying N\n",
    "5. Plot the likelihood each test fails for a given sample size.\n",
    "\n",
    "Below is a snippet of code that runs 20 tests against one sample of data, and determines if the test determines it is normal or not. For an alpha value of 0.05, you would expect about 1 of the tests to fail on average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality_script(sample_size, test_type, repetitions = 100):\n",
    "    distribution = stats.norm()\n",
    "    data = distribution.rvs(sample_size)\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    for i in range(repetitions):\n",
    "        distribution = stats.norm()\n",
    "        data = distribution.rvs(sample_size)\n",
    "    \n",
    "        if test_type == \"sw\":\n",
    "            statistic, p = stats.shapiro(data)\n",
    "        elif test_type == \"cs\":\n",
    "            statistic, p = stats.normaltest(data)\n",
    "        elif test_type == \"ks\":\n",
    "            statistic, p = stats.kstest(data, cdf = 'norm')\n",
    "        elif test_type == \"jb\":\n",
    "            statistic, p, skew, kurtosis = stattools.jarque_bera(data)\n",
    "        \n",
    "        if p > 0.05:\n",
    "            passed += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "        \n",
    "    return failed/(passed+failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:1806: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8af338989ec947cab66427a02d62526f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8af338989ec947cab66427a02d62526f.vega-embed details,\n",
       "  #altair-viz-8af338989ec947cab66427a02d62526f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8af338989ec947cab66427a02d62526f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8af338989ec947cab66427a02d62526f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8af338989ec947cab66427a02d62526f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-36683d052866d1e8f03505cc079324cd.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"Test\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Sample\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Failed\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats import stattools\n",
    "from scipy import stats\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "sample_sizes = [10, 30, 50, 100, 1000, 5000]\n",
    "#sample_sizes = np.linspace(10, max_sample_size, 20, dtype=np.int)\n",
    "\n",
    "test_types = [\"sw\", \"cs\", \"ks\", \"jb\"]\n",
    "data = []\n",
    "\n",
    "for size in sample_sizes:\n",
    "    for test in test_types:\n",
    "        p_fail = normality_script(size, test)\n",
    "        row = [test,size,p_fail]\n",
    "        data.append(row)\n",
    "        \n",
    "\n",
    "df = pd.DataFrame(data, columns=['Test', 'Sample', 'Failed'])\n",
    "\n",
    "\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x='Sample',\n",
    "    y='Failed',\n",
    "    color = 'Test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 passed and 1 failed\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "passed = 0\n",
    "failed = 0\n",
    "for i in range(20):\n",
    "    distribution = stats.norm()\n",
    "    data = distribution.rvs(sample_size)\n",
    "    stat, p = stats.normaltest(data)\n",
    "    if p > 0.05:\n",
    "        passed += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "print(\"{} passed and {} failed\".format(passed, failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions see `solutions/many_normal_tests.py`*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
